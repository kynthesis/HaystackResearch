{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN38WT1QR/1+Nx+WFt1Pk1W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kynthesis/HaystackResearch/blob/main/WebSearch_LFQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cekDh9CALGdO",
        "outputId": "ab1136c1-5d61-4b38-ca96-c7f0e7504270"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 18 05:44:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC6Mx8IMim3h"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "serper_api_key = getpass(\"Enter Serper API key:\")\n",
        "openai_api_key = getpass(\"Enter OpenAI API key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N97Kk_aYLyX_",
        "outputId": "2baf6260-7f08-4817-fe2f-7973ccf67e27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Serper API key:··········\n",
            "Enter OpenAI API key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import PromptNode, PromptTemplate, TopPSampler\n",
        "from haystack.nodes.retriever.web import WebRetriever\n",
        "from haystack.pipelines import WebQAPipeline"
      ],
      "metadata": {
        "id": "3QYGlqovNKeo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"\n",
        "Synthesize a comprehensive answer from the following most relevant paragraphs and the given question.\n",
        "Provide a clear and concise response that summarizes the key points and information presented in the paragraphs.\n",
        "Your answer should be in your own words and be no longer than 50 words.\n",
        "\\n\\n Paragraphs: {documents} \\n\\n Question: {query} \\n\\n Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_node = PromptNode(\n",
        "    \"text-davinci-003\", default_prompt_template=PromptTemplate(prompt_text), api_key=openai_api_key, max_length=256\n",
        ")\n",
        "\n",
        "web_retriever = WebRetriever(api_key=serper_api_key, top_search_results=5, mode=\"preprocessed_documents\", top_k=30)\n",
        "\n",
        "pipeline = WebQAPipeline(retriever=web_retriever, prompt_node=prompt_node, sampler=TopPSampler(top_p=0.8))"
      ],
      "metadata": {
        "id": "si2TeYJ2NdHv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What are the differences between ChatGPT-3 and ChatGPT-4?\",\n",
        "    \"When should Extractive QA and Generative QA be used?\",\n",
        "    \"What are the differences between Langchain and Haystack?\"\n",
        "]"
      ],
      "metadata": {
        "id": "sAaw6P1lNhPA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger(\"haystack.nodes.retriever.link_content\")\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "logger = logging.getLogger(\"boilerpy3\")\n",
        "logger.setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "1aTPhvyoPz-6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in questions:\n",
        "    print(f\"Question: {q}\")\n",
        "    response = pipeline.run(query=q)\n",
        "    print(f\"Answer: {response['results'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tzRW762NyeQ",
        "outputId": "dd1afb6f-df7c-478a-cb59-fcb5f174a25d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the differences between ChatGPT-3 and ChatGPT-4?\n",
            "Answer: ChatGPT-4 is more powerful than ChatGPT-3, with more parameters, better understanding of context, domain-wise expertise, multi-language capabilities, and the ability to process images as well as text. It has a greater capacity to process information, a higher accuracy of responses, and fewer unsafe responses.\n",
            "Question: When should Extractive QA and Generative QA be used?\n",
            "Answer: Extractive QA should be used when the answer is present in a given context, such as a text, table, or HTML. Generative QA can be used when the answer must be generated based on a context, or when no context is provided and the answer must be completely generated by a model.\n",
            "Question: What are the differences between Langchain and Haystack?\n",
            "Answer: LangChain and Haystack both offer different approaches to building language applications. LangChain uses LLMs and Agents to delegate actions to build powerful applications, while Haystack focuses more on building large-scale search systems, question-answering, summarization and conversational AI. Haystack is currently working on adding Agent components to their platform.\n"
          ]
        }
      ]
    }
  ]
}